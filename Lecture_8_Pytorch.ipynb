{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch-GPU",
      "language": "python",
      "name": "pyt-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vik-ahlawat/Data_Science-/blob/main/Lecture_8_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VNIH93hD-Ya"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "This will be the final lecture, today we will first have a brief introduction of deep learning, then we will look at some basics of using PyTorch to implement some simple models in deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Section (Start)\n",
        "What is Neural Network:\n",
        "1. [Recommended youtube video with great visual helpers](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=4)\n",
        "# Basic Section (End)"
      ],
      "metadata": {
        "id": "jJYsdl4IbsO6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fCZYu2D-Yc"
      },
      "source": [
        "# Deep Learning Libraries\n",
        "\n",
        "There are many deep learning libraries available, the most common ones for python are\n",
        "\n",
        "- TensorFlow, Keras\n",
        "- PyTorch\n",
        "\n",
        "Working with tensorflow requires going into lot of details of the contruction of the computation graph, whereas Keras is a higher level interface for tensorflow. Tensorflow is very popular in the industry and good for production code.\n",
        "\n",
        "PyTorch can be used as low level interface, but is much more user-friendly than tensorflow, but it also has a higher level interface. Pytorch is more popular in the research community.\n",
        "\n",
        "## Main features that any deep learning library should provide\n",
        "\n",
        "No matter what library or language you use, the main features provided by a deep learning library are\n",
        "1. Use the GPU to speed up computation\n",
        "2. Ability to do automatic differentiation\n",
        "3. Useful library functions for common architectures and optimization algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUDYHi8D-Yd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "We will look at all of the above in pytorch.\n",
        "The best way to think about pytorch is that its numpy + GPU + autograd.\n",
        "\n",
        "You can install it with\n",
        "\n",
        "```conda install pytorch```.\n",
        "\n",
        "Alternatively (and recommended), run this notebook in Google Colab-- it provides an environment with all of the PyTorch dependencies plus a GPU free of charge."
      ],
      "metadata": {
        "id": "yPut46JUDh-E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCdvNHW0D-Ye"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpWzZewHD-Yi"
      },
      "source": [
        "The equivalent object to numpy arrays in pytorch are called tensors, but they are just multidimensional arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t78yenP1D-Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17173026-7007-4d69-97bf-dbdc7b9b22ce"
      },
      "source": [
        "torch.tensor([2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efg1UeizD-Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b43b0d-b526-4e46-8314-0c052c846c6a"
      },
      "source": [
        "torch.zeros((5, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BlufhDpD-Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb095a24-eeea-4fb4-b720-ea76dec79310"
      },
      "source": [
        "x = torch.ones((5, 5))\n",
        "print(type(x))\n",
        "print(x)\n",
        "print(2*x +5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "tensor([[7., 7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7., 7.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwCz7O1wD-Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89917ad4-fae4-45c3-9e4b-21c507978322"
      },
      "source": [
        "torch.randn(5, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6201,  1.0562, -0.8070,  1.6514, -0.9157],\n",
              "        [-0.1631, -1.2164, -1.7736, -0.2871, -0.3023],\n",
              "        [-0.9513, -0.3931,  0.4196,  0.3535,  0.9642],\n",
              "        [-0.6495, -0.1778,  1.7908,  0.9826, -0.1174],\n",
              "        [-2.1790,  2.0435, -1.2822, -0.4264,  0.2710]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fHiY5VKD-Yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1564a74e-9d62-4899-8652-d9bc2be44d44"
      },
      "source": [
        "x = torch.rand(25)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5121, 0.6288, 0.1132, 0.7700, 0.1522, 0.8381, 0.7997, 0.9358, 0.3138,\n",
              "        0.2970, 0.0024, 0.2669, 0.0510, 0.8862, 0.8821, 0.3127, 0.4198, 0.9081,\n",
              "        0.5322, 0.2821, 0.6545, 0.2972, 0.1414, 0.6394, 0.9927])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_QKyI7hD-Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f0df81-5250-4299-967f-e2b3b34348c3"
      },
      "source": [
        "x = x.reshape(-1, 5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5121, 0.6288, 0.1132, 0.7700, 0.1522],\n",
              "        [0.8381, 0.7997, 0.9358, 0.3138, 0.2970],\n",
              "        [0.0024, 0.2669, 0.0510, 0.8862, 0.8821],\n",
              "        [0.3127, 0.4198, 0.9081, 0.5322, 0.2821],\n",
              "        [0.6545, 0.2972, 0.1414, 0.6394, 0.9927]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9fwJoSD-Y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe37b57-96d0-4088-bf73-ed344fefd990"
      },
      "source": [
        "print(torch.arange(10))\n",
        "print(torch.eye(5))\n",
        "print(torch.linspace(0, 1, 10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cix7EXwSD-Y7"
      },
      "source": [
        "Some functions are a bit different"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(5, 5)\n",
        "x = np.ones((5, 1))\n",
        "print(A)\n",
        "print(x)\n",
        "A @ x"
      ],
      "metadata": {
        "id": "fRrYVBDmjLpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a174e41-e394-4f8f-ab7b-d0111b8ff4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.40907469e-01 7.41801097e-01 3.26276028e-01 1.16395627e-01\n",
            "  2.00541451e-01]\n",
            " [6.01444328e-01 1.66794535e-01 5.48138376e-01 3.76958231e-01\n",
            "  2.84359207e-01]\n",
            " [2.64407668e-01 2.95378340e-02 8.14819979e-01 9.92231323e-01\n",
            "  5.76579647e-01]\n",
            " [2.42525726e-01 9.79025068e-01 4.40877993e-01 6.93987708e-01\n",
            "  8.82807214e-01]\n",
            " [6.72827172e-01 2.03056631e-04 4.05482473e-02 6.76542934e-01\n",
            "  4.71464277e-01]]\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.22592167],\n",
              "       [1.97769468],\n",
              "       [2.67757645],\n",
              "       [3.23922371],\n",
              "       [1.86158569]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_ = torch.rand((5, 5))\n",
        "x_ = torch.rand(5, 1)\n",
        "print(A_)\n",
        "print(x_)\n",
        "A_ @ x_"
      ],
      "metadata": {
        "id": "npGWD47jicvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74276f25-cfed-4179-d5b7-7adc092a6716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4749, 0.2277, 0.8200, 0.8699, 0.2063],\n",
            "        [0.2178, 0.5834, 0.3493, 0.4329, 0.7640],\n",
            "        [0.9455, 0.1247, 0.6293, 0.4281, 0.1063],\n",
            "        [0.4195, 0.1590, 0.2659, 0.2342, 0.2512],\n",
            "        [0.1106, 0.3212, 0.4249, 0.4877, 0.2337]])\n",
            "tensor([[5.3644e-07],\n",
            "        [3.8466e-01],\n",
            "        [3.5391e-01],\n",
            "        [4.8614e-02],\n",
            "        [3.4319e-02]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4272],\n",
              "        [0.3953],\n",
              "        [0.2951],\n",
              "        [0.1753],\n",
              "        [0.3057]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BukQIL5D-Y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9964dc4d-b865-476c-c92a-57f277eeda7e"
      },
      "source": [
        "A = torch.ones((5, 5))\n",
        "x = torch.ones(5, 1)\n",
        "print(A)\n",
        "print(x)\n",
        "A @ x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.],\n",
              "        [5.],\n",
              "        [5.],\n",
              "        [5.],\n",
              "        [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "?np.ones"
      ],
      "metadata": {
        "id": "n2XG-EU0jUci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YHvvy4D-Y-"
      },
      "source": [
        "?torch.ones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpEwcH-JD-ZA"
      },
      "source": [
        "You can convert tensors to a numpy array that shares its memory with the pytorch tensor -> to use more library that are compatible to numpy but not pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MquNPK71D-ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904b7dc8-6fc2-4525-e1ff-266dd2ad9217"
      },
      "source": [
        "x = torch.ones(5, 5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOeMqFrOD-ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a5a6e2-9616-41e6-f3de-5a8e4c851a74"
      },
      "source": [
        "xn = x.numpy()\n",
        "print(type(xn))\n",
        "xn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlG0x9xD-ZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4e1e0b-dfce-469f-a208-39e810498c03"
      },
      "source": [
        "# Changes in Numpy will cause changes in Tensor\n",
        "xn[4, 2] = 10\n",
        "xn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1., 10.,  1.,  1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6qJIsID-ZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd2d21f-fdd5-4ea8-f0f4-931cbad737cb"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1., 10.,  1.,  1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDnSshCXD-ZL"
      },
      "source": [
        "## Using the GPU\n",
        "\n",
        "The GPU (Graphical Processing Unit) is a separate processing unit that is specialized to handle bulk computations required for rendering high quality graphics. It mainly consists of a large number of processor cores that are individually very slow, but because of their sheer number (around 2000) they can churn through computations very quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmJ0hjO5D-ZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d504e57-fe45-4091-fe47-3f6c88d31679"
      },
      "source": [
        "import torch\n",
        "\n",
        "\"\"\"\n",
        "CUDA is a parallel computing platform\n",
        "and application programming interface\n",
        "that allows software to use certain types\n",
        "of graphics processing units for general purpose processing\n",
        "\"\"\"\n",
        "# CUDA -> Recommend CME213 (C++)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0kadMeJD-ZN"
      },
      "source": [
        "Installing the GPU drivers and the CUDA toolkit can be quite messy, so if you just want to experiment with GPUs and deep learning libraries, you can use [Google colaboratory](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtE0kLaD-ZO"
      },
      "source": [
        "gpu = torch.device(\"cuda\")\n",
        "cpu = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu, cpu"
      ],
      "metadata": {
        "id": "urO7Jofk5JyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0123db-08ed-46e5-c6fe-ecbb721513b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda'), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESIE5J08D-ZS"
      },
      "source": [
        "A = torch.rand(100, 100)\n",
        "B = torch.rand(100, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6VNz5SzD-ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4c322a-4537-4724-a9bb-5782091f0adf"
      },
      "source": [
        "A.to('cuda') @ B.to('cuda') # .to('cuda') moves the PyTorch tensors A and B from the CPU"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[23.6652, 23.9288, 24.3143,  ..., 23.2676, 25.4306, 27.2386],\n",
              "        [24.7167, 24.6607, 25.4587,  ..., 25.6353, 26.9865, 27.9898],\n",
              "        [24.1564, 22.9828, 21.9076,  ..., 22.3473, 22.8977, 24.7727],\n",
              "        ...,\n",
              "        [23.8090, 26.2407, 25.4452,  ..., 26.1298, 24.4618, 27.8971],\n",
              "        [27.5789, 28.5560, 28.2434,  ..., 29.4338, 29.4395, 28.1920],\n",
              "        [20.6508, 21.3678, 21.8029,  ..., 20.7227, 20.7430, 23.1453]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXjtNNqtD-ZW"
      },
      "source": [
        "A_gpu = A.to(gpu)\n",
        "B_gpu = B.to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krIHa3ErD-ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f375031-10eb-4cec-a55a-c39eaf64fb10"
      },
      "source": [
        "A_gpu @ B_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[23.6652, 23.9288, 24.3143,  ..., 23.2676, 25.4306, 27.2386],\n",
              "        [24.7167, 24.6607, 25.4587,  ..., 25.6353, 26.9865, 27.9898],\n",
              "        [24.1564, 22.9828, 21.9076,  ..., 22.3473, 22.8977, 24.7727],\n",
              "        ...,\n",
              "        [23.8090, 26.2407, 25.4452,  ..., 26.1298, 24.4618, 27.8971],\n",
              "        [27.5789, 28.5560, 28.2434,  ..., 29.4338, 29.4395, 28.1920],\n",
              "        [20.6508, 21.3678, 21.8029,  ..., 20.7227, 20.7430, 23.1453]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oi8M-GD-Zc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525fb248-8ff5-4492-8a8e-01fd529d81f1"
      },
      "source": [
        "C_gpu = A_gpu @ B_gpu\n",
        "C = C_gpu.to(cpu)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[23.6652, 23.9288, 24.3143,  ..., 23.2676, 25.4306, 27.2386],\n",
              "        [24.7167, 24.6607, 25.4587,  ..., 25.6353, 26.9865, 27.9898],\n",
              "        [24.1564, 22.9828, 21.9076,  ..., 22.3473, 22.8977, 24.7727],\n",
              "        ...,\n",
              "        [23.8090, 26.2407, 25.4452,  ..., 26.1298, 24.4618, 27.8971],\n",
              "        [27.5789, 28.5560, 28.2434,  ..., 29.4338, 29.4395, 28.1920],\n",
              "        [20.6508, 21.3678, 21.8029,  ..., 20.7227, 20.7430, 23.1453]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vICVTE1wD-Zq"
      },
      "source": [
        "## Speedup from GPU\n",
        "`%%timeit` is a Jupyter Notebook magic command that is used to measure the execution time of a Python code snippet. When you add `%%timeit` at the beginning of a cell in a Jupyter Notebook, it will run the code in the cell multiple times and measure the average execution time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4raRnuw1D-Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dc5ab7-71a2-48c8-f002-1158c213de15"
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000, 3000)\n",
        "B = torch.rand(3000, 3000)\n",
        "for i in range(5):\n",
        "    B = torch.mm(A, B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.37 s ± 351 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch47eB6OD-Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f06917-da04-4709-9a9a-1a4abcac6171"
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000, 3000, device=gpu)\n",
        "B = torch.rand(3000, 3000, device=gpu)\n",
        "for i in range(5):\n",
        "    B = torch.mm(A, B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70.5 ms ± 1.65 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDNQLaL6D-Zu"
      },
      "source": [
        "## Automatic Differentiation\n",
        "\n",
        "PyTorch is designed for automatic differentiation. PyTorch uses dynamic computation graphs to compute the gradients of the parameters.\n",
        "\n",
        "When performing operations on tensors with `requires_grad=True`, PyTorch builds a computation graph, recording each operation (like `+`, `*`, `mm`, etc.). This graph tells PyTorch how to compute derivatives during `backward()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r6mfgjHD-Zv"
      },
      "source": [
        "# initiate parameters w and b\n",
        "x = torch.tensor([2.0])\n",
        "w = torch.tensor([5.0], requires_grad=True)\n",
        "b = torch.tensor([2.0], requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezGUNqXD-Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b795e50b-51db-4396-83c9-ffc9f5c4de51"
      },
      "source": [
        "y = w * x + b\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Y_WzasD-Z0"
      },
      "source": [
        "Define an error for your function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7oYMHFD-Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c98b717-b6a4-40d4-8974-43b31e8c5390"
      },
      "source": [
        "# define loss function\n",
        "loss = torch.linalg.vector_norm(y - 13)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<LinalgVectorNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient is not computed unless starting backpropagation\n",
        "w.grad"
      ],
      "metadata": {
        "id": "6VhXA6FXJW-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMhtVXAhD-Z5"
      },
      "source": [
        "Calling `x.backward()` on any tensor forces pytorch to compute all the gradients of the tensors used to compute `x` which had the `requires_grad` flag set to `True`. The computed gradient will be stored in the `.grad` property of the tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PIU90uoD-Z5"
      },
      "source": [
        "# backpropogation, compute gradients\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYbns6g4D-Z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d064f523-235a-43c6-c3f2-fdb983d9f69f"
      },
      "source": [
        "w.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MYesARFD-Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2de3dbe-e7a5-4f68-d8e5-044de72bf64e"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tell PyTorch to skip the gradient calculations of tensors using `torch.no_grad()`, which can help to reduce the memory usage and speed up computations. If you don't use `torch.no_grad()`, PyTorch will track this operation, and the updated tensor will be part of the computation graph."
      ],
      "metadata": {
        "id": "a9GBX-JwVykN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDhPOJHRD-aA"
      },
      "source": [
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad # when we update w and b, do not update gradients\n",
        "    b -= 0.3 * b.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TlUBDHaD-aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfe21a5-6e16-41e8-e3ad-0acdd5f1da79"
      },
      "source": [
        "w, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5.0200], requires_grad=True), tensor([2.3000], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj85MTj2D-aF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1d0fad-184c-4a4a-9b3e-bf3e5a9348d2"
      },
      "source": [
        "w.grad, b.grad # gradient doesn't change"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.]), tensor([-1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, gradients will accumulate. That means each time you call `loss.backward()`, the new gradients are added to `.grad`. We need to manually clear them."
      ],
      "metadata": {
        "id": "EWWVtZYNK22R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3UbDFA7D-aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ac9970-2354-42be-cc7b-da1b091cd897"
      },
      "source": [
        "# the gradients will accumulate and lead to incorrect updates and slower convergence.\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "w.grad, b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.]), tensor([0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgA5bqxD-aL"
      },
      "source": [
        "y = w * x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhEnrtmQD-aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3896e0b1-2d19-4046-c991-3707ec84dec0"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.3400], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJYE5aRpD-aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943ab230-e7f3-40df-8d0d-6bfbc5f3fb03"
      },
      "source": [
        "loss = torch.norm(y - 13)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6600, grad_fn=<LinalgVectorNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBLYqopxD-aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4f0a44-41e2-4afb-ee21-fa0c288c575a"
      },
      "source": [
        "loss.backward()\n",
        "w.grad, b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.]), tensor([-1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNbj9oDlD-aS"
      },
      "source": [
        "### Making it more compact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlQ60VuqD-aS"
      },
      "source": [
        "def model_fn(x, w, b):\n",
        "    return w * x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zZHeiwJD-aV"
      },
      "source": [
        "def loss_fn(y, yt):\n",
        "    return torch.norm(y - yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7drmZAzD-aX"
      },
      "source": [
        "w = torch.tensor([5.0], requires_grad=True)\n",
        "b = torch.tensor([2.0], requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSogMXf-D-aY"
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "yt = torch.tensor([13.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BNsdU-D-aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8414fa79-3556-45ad-e93b-118466b3090f"
      },
      "source": [
        "y = model_fn(x, w, b)\n",
        "loss = loss_fn(y, yt)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "    w -= 0.05 * w.grad\n",
        "    b -= 0.05 * b.grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(f\" w = {w}\\n b = {b}\\n y = {y}\\n loss = {loss}\")\n",
        "# note that 'loss' indicates the loss for the previous m,c values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " w = tensor([5.1000], requires_grad=True)\n",
            " b = tensor([2.0500], requires_grad=True)\n",
            " y = tensor([12.], grad_fn=<AddBackward0>)\n",
            " loss = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kRdaQe6D-ab"
      },
      "source": [
        "### Training loop explained"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Forward propagation to get predicted $\\hat{y}$\n",
        "2. Get the loss by loss_fun(y, $\\hat{y}$)\n",
        "3. Backward propagation to get the gradient\n",
        "4. Update parameters\n",
        "5. Repeat 1 ~ 4 until convergence"
      ],
      "metadata": {
        "id": "vNdBCLA1yTn4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alq94bPxD-ac"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdYDtWDD-ae"
      },
      "source": [
        "def model_fn(x, w, b):\n",
        "    return w @ x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Cvos0BD-af"
      },
      "source": [
        "def loss_fn(y, yt):\n",
        "    return torch.norm(y - yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCjbW7HD-ah"
      },
      "source": [
        "w = torch.rand((5, 5), requires_grad=True)\n",
        "b = torch.ones((5, 1), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsITRCClD-ai"
      },
      "source": [
        "x = torch.randn(5, 100)\n",
        "yt = torch.randn(1, 100)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFs5CphAD-al",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6b686b7-c51f-4ab8-fb61-4d2672c4b32b"
      },
      "source": [
        "for i in range(50):\n",
        "    # 1. Forward\n",
        "    y = model_fn(x, w, b)\n",
        "    # 2. Get loss\n",
        "    loss = loss_fn(y, yt)\n",
        "    # 3. backward\n",
        "    loss.backward()\n",
        "    # 4. Update\n",
        "    with torch.no_grad():\n",
        "        w -= 0.05 * w.grad\n",
        "        b -= 0.05 * b.grad\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "    losses += [loss.item()]\n",
        "    print(f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 43.12593078613281\n",
            "loss = 38.73484802246094\n",
            "loss = 34.77571487426758\n",
            "loss = 31.318378448486328\n",
            "loss = 28.419946670532227\n",
            "loss = 26.105955123901367\n",
            "loss = 24.354421615600586\n",
            "loss = 23.09492301940918\n",
            "loss = 22.226896286010742\n",
            "loss = 21.64614486694336\n",
            "loss = 21.26414680480957\n",
            "loss = 21.014719009399414\n",
            "loss = 20.8520565032959\n",
            "loss = 20.74576759338379\n",
            "loss = 20.67607307434082\n",
            "loss = 20.63019561767578\n",
            "loss = 20.59988021850586\n",
            "loss = 20.57977867126465\n",
            "loss = 20.56640625\n",
            "loss = 20.557485580444336\n",
            "loss = 20.551517486572266\n",
            "loss = 20.547517776489258\n",
            "loss = 20.544830322265625\n",
            "loss = 20.54302406311035\n",
            "loss = 20.541805267333984\n",
            "loss = 20.540985107421875\n",
            "loss = 20.540428161621094\n",
            "loss = 20.540054321289062\n",
            "loss = 20.5398006439209\n",
            "loss = 20.539627075195312\n",
            "loss = 20.53951072692871\n",
            "loss = 20.539432525634766\n",
            "loss = 20.539377212524414\n",
            "loss = 20.539339065551758\n",
            "loss = 20.539316177368164\n",
            "loss = 20.53929901123047\n",
            "loss = 20.539289474487305\n",
            "loss = 20.53927993774414\n",
            "loss = 20.539274215698242\n",
            "loss = 20.539270401000977\n",
            "loss = 20.539268493652344\n",
            "loss = 20.53926658630371\n",
            "loss = 20.53926658630371\n",
            "loss = 20.53926658630371\n",
            "loss = 20.539264678955078\n",
            "loss = 20.539262771606445\n",
            "loss = 20.539262771606445\n",
            "loss = 20.539264678955078\n",
            "loss = 20.539262771606445\n",
            "loss = 20.539260864257812\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Final w: {w}')\n",
        "print(f'Final b: {b}')"
      ],
      "metadata": {
        "id": "gYoD9g_NMsWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0160c2-7e69-42d7-ebe6-8be9b3037ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final w: tensor([[ 0.1988, -0.1309, -0.0467, -0.0519,  0.0991],\n",
            "        [ 0.1988, -0.1309, -0.0467, -0.0519,  0.0991],\n",
            "        [ 0.1988, -0.1309, -0.0467, -0.0519,  0.0991],\n",
            "        [ 0.1988, -0.1310, -0.0467, -0.0519,  0.0991],\n",
            "        [ 0.1988, -0.1310, -0.0467, -0.0519,  0.0991]], requires_grad=True)\n",
            "Final b: tensor([[-0.0513],\n",
            "        [-0.0513],\n",
            "        [-0.0513],\n",
            "        [-0.0513],\n",
            "        [-0.0513]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7iYj2eD-an"
      },
      "source": [
        "## Using Library functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xg-kywmD-an"
      },
      "source": [
        "# create simple feedforward neural network (MLP)\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(5, 5), # F(WX + B), takes input vectors of size 5 and produces output vectors of size 5.\n",
        "    torch.nn.ReLU(), # Applies ReLU activation function\n",
        "    torch.nn.Linear(5, 1), # output layer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OocRUb9D-ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6069804-675e-4186-8bfe-2f76f7eb42a8"
      },
      "source": [
        "list(model.parameters()) # automatically initialize parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0502, -0.1427,  0.4463,  0.4034, -0.4111],\n",
              "         [-0.2611,  0.3585, -0.0434,  0.2352, -0.2394],\n",
              "         [-0.0988,  0.0600,  0.3566, -0.0117,  0.0442],\n",
              "         [-0.2810,  0.2298,  0.2913,  0.3164,  0.0653],\n",
              "         [ 0.3525, -0.3680, -0.4081, -0.0025,  0.1025]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.3352,  0.1273, -0.3896, -0.3816,  0.2401], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.3821, -0.3142,  0.2906, -0.4443,  0.0521]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1529], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgBOzYv5D-aq"
      },
      "source": [
        "# mean square loss → MSE = (1/n) * sum((y_pred - y_true)^2)\n",
        "loss_fn = torch.nn.MSELoss(reduction=\"sum\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bdGByKKD-as"
      },
      "source": [
        "x = torch.randn(100, 5)\n",
        "yt = torch.randn(100, 1)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KupJGFEFD-at"
      },
      "source": [
        "## Using the optim package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ac8_-reD-au"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03) # pass all trainable parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`optimizer.step()` is used to update the model parameters based on the gradients computed during backpropagation. During training, the optimizer computes the gradients of the loss function with respect to the model parameters\n",
        "  \n",
        "`optimizer.zero_grad()` is used to set the gradients of all the model parameters to zero before computing the gradients for the next batch of data. If we don't zero out the gradients before computing the gradients for the next batch, the gradients will accumulate, leading to incorrect updates and slower convergence."
      ],
      "metadata": {
        "id": "v1T-hdaSYBU7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtdxXUcRD-az",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "858bdd7c-86d3-4974-9dbc-3bf96789b56f"
      },
      "source": [
        "for i in range(1000):\n",
        "    y = model(x)\n",
        "    loss = loss_fn(y, yt)\n",
        "    loss.backward()\n",
        "\n",
        "    # make the parameter to take a step -> update the parameter\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses += [loss.item()]\n",
        "    print(f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 99.29678344726562\n",
            "loss = 94.59911346435547\n",
            "loss = 91.69466400146484\n",
            "loss = 89.49272155761719\n",
            "loss = 87.80821990966797\n",
            "loss = 86.51478576660156\n",
            "loss = 85.58882904052734\n",
            "loss = 84.8089828491211\n",
            "loss = 84.1367416381836\n",
            "loss = 83.55131530761719\n",
            "loss = 83.04520416259766\n",
            "loss = 82.50395202636719\n",
            "loss = 81.90431213378906\n",
            "loss = 81.33540344238281\n",
            "loss = 80.76554870605469\n",
            "loss = 80.13177490234375\n",
            "loss = 79.44314575195312\n",
            "loss = 78.6986083984375\n",
            "loss = 78.02889251708984\n",
            "loss = 77.47087097167969\n",
            "loss = 76.97418212890625\n",
            "loss = 76.32892608642578\n",
            "loss = 75.63391876220703\n",
            "loss = 74.98994445800781\n",
            "loss = 74.46410369873047\n",
            "loss = 73.86978149414062\n",
            "loss = 73.19276428222656\n",
            "loss = 72.56536865234375\n",
            "loss = 72.00039672851562\n",
            "loss = 71.46971130371094\n",
            "loss = 70.90898132324219\n",
            "loss = 70.33007049560547\n",
            "loss = 69.75514221191406\n",
            "loss = 69.30944061279297\n",
            "loss = 68.83907318115234\n",
            "loss = 68.29731750488281\n",
            "loss = 67.66146850585938\n",
            "loss = 67.0216293334961\n",
            "loss = 66.45867156982422\n",
            "loss = 65.8777084350586\n",
            "loss = 65.32731628417969\n",
            "loss = 64.86297607421875\n",
            "loss = 64.51231384277344\n",
            "loss = 64.23001098632812\n",
            "loss = 63.94352722167969\n",
            "loss = 63.656246185302734\n",
            "loss = 63.37522888183594\n",
            "loss = 63.0766716003418\n",
            "loss = 62.82828140258789\n",
            "loss = 62.64258575439453\n",
            "loss = 62.45936965942383\n",
            "loss = 62.26205825805664\n",
            "loss = 62.07136154174805\n",
            "loss = 61.879581451416016\n",
            "loss = 61.727725982666016\n",
            "loss = 61.57844924926758\n",
            "loss = 61.33677291870117\n",
            "loss = 61.0892333984375\n",
            "loss = 60.82532501220703\n",
            "loss = 60.53175354003906\n",
            "loss = 60.20723342895508\n",
            "loss = 60.07324981689453\n",
            "loss = 59.859352111816406\n",
            "loss = 59.52179718017578\n",
            "loss = 59.482086181640625\n",
            "loss = 59.35591506958008\n",
            "loss = 59.122962951660156\n",
            "loss = 58.64441680908203\n",
            "loss = 58.43218994140625\n",
            "loss = 58.35930633544922\n",
            "loss = 58.1991081237793\n",
            "loss = 57.91693878173828\n",
            "loss = 57.84027099609375\n",
            "loss = 57.67261505126953\n",
            "loss = 57.636287689208984\n",
            "loss = 57.4576416015625\n",
            "loss = 57.10560607910156\n",
            "loss = 56.80257034301758\n",
            "loss = 56.47858810424805\n",
            "loss = 56.30647659301758\n",
            "loss = 55.975223541259766\n",
            "loss = 55.682159423828125\n",
            "loss = 55.357662200927734\n",
            "loss = 55.094573974609375\n",
            "loss = 54.84562683105469\n",
            "loss = 54.67351531982422\n",
            "loss = 54.41008758544922\n",
            "loss = 54.16084671020508\n",
            "loss = 53.79678726196289\n",
            "loss = 53.59334945678711\n",
            "loss = 53.28062057495117\n",
            "loss = 53.1558723449707\n",
            "loss = 52.919708251953125\n",
            "loss = 52.88264465332031\n",
            "loss = 52.82591247558594\n",
            "loss = 52.71412658691406\n",
            "loss = 52.79884338378906\n",
            "loss = 52.739601135253906\n",
            "loss = 52.73310089111328\n",
            "loss = 52.72907638549805\n",
            "loss = 52.77433395385742\n",
            "loss = 52.77479934692383\n",
            "loss = 52.71693420410156\n",
            "loss = 52.712467193603516\n",
            "loss = 52.6794319152832\n",
            "loss = 52.64572525024414\n",
            "loss = 52.61867904663086\n",
            "loss = 52.57645797729492\n",
            "loss = 52.56946563720703\n",
            "loss = 52.539405822753906\n",
            "loss = 52.54560852050781\n",
            "loss = 52.522850036621094\n",
            "loss = 52.50159454345703\n",
            "loss = 52.47978973388672\n",
            "loss = 52.5009651184082\n",
            "loss = 52.46707534790039\n",
            "loss = 52.4581413269043\n",
            "loss = 52.43877410888672\n",
            "loss = 52.46125030517578\n",
            "loss = 52.45169448852539\n",
            "loss = 52.462467193603516\n",
            "loss = 52.480987548828125\n",
            "loss = 52.4485969543457\n",
            "loss = 52.43543243408203\n",
            "loss = 52.38975524902344\n",
            "loss = 52.38505935668945\n",
            "loss = 52.39733123779297\n",
            "loss = 52.40803146362305\n",
            "loss = 52.40503692626953\n",
            "loss = 52.38969802856445\n",
            "loss = 52.40654754638672\n",
            "loss = 52.39531707763672\n",
            "loss = 52.33679962158203\n",
            "loss = 52.335548400878906\n",
            "loss = 52.35605239868164\n",
            "loss = 52.335166931152344\n",
            "loss = 52.339454650878906\n",
            "loss = 52.35392761230469\n",
            "loss = 52.349796295166016\n",
            "loss = 52.353515625\n",
            "loss = 52.356231689453125\n",
            "loss = 52.32243728637695\n",
            "loss = 52.3165168762207\n",
            "loss = 52.37795639038086\n",
            "loss = 52.313289642333984\n",
            "loss = 52.32292175292969\n",
            "loss = 52.34142303466797\n",
            "loss = 52.352439880371094\n",
            "loss = 52.34935760498047\n",
            "loss = 52.321067810058594\n",
            "loss = 52.29960250854492\n",
            "loss = 52.30312728881836\n",
            "loss = 52.315189361572266\n",
            "loss = 52.299713134765625\n",
            "loss = 52.27182388305664\n",
            "loss = 52.277915954589844\n",
            "loss = 52.27653884887695\n",
            "loss = 52.288658142089844\n",
            "loss = 52.298824310302734\n",
            "loss = 52.315330505371094\n",
            "loss = 52.286075592041016\n",
            "loss = 52.24691390991211\n",
            "loss = 52.3055305480957\n",
            "loss = 52.27528762817383\n",
            "loss = 52.25799560546875\n",
            "loss = 52.278648376464844\n",
            "loss = 52.24547576904297\n",
            "loss = 52.23732376098633\n",
            "loss = 52.2559814453125\n",
            "loss = 52.2278938293457\n",
            "loss = 52.26275634765625\n",
            "loss = 52.2291374206543\n",
            "loss = 52.20905303955078\n",
            "loss = 52.301063537597656\n",
            "loss = 52.229549407958984\n",
            "loss = 52.231868743896484\n",
            "loss = 52.25147247314453\n",
            "loss = 52.22247314453125\n",
            "loss = 52.20951843261719\n",
            "loss = 52.23011779785156\n",
            "loss = 52.23631286621094\n",
            "loss = 52.220680236816406\n",
            "loss = 52.21775436401367\n",
            "loss = 52.23603820800781\n",
            "loss = 52.194461822509766\n",
            "loss = 52.2313232421875\n",
            "loss = 52.19345474243164\n",
            "loss = 52.19870376586914\n",
            "loss = 52.232666015625\n",
            "loss = 52.22728729248047\n",
            "loss = 52.21784591674805\n",
            "loss = 52.20391082763672\n",
            "loss = 52.19740295410156\n",
            "loss = 52.19499588012695\n",
            "loss = 52.23056411743164\n",
            "loss = 52.20256042480469\n",
            "loss = 52.183860778808594\n",
            "loss = 52.15829849243164\n",
            "loss = 52.197540283203125\n",
            "loss = 52.178836822509766\n",
            "loss = 52.15254211425781\n",
            "loss = 52.181785583496094\n",
            "loss = 52.16825485229492\n",
            "loss = 52.168792724609375\n",
            "loss = 52.186607360839844\n",
            "loss = 52.13855743408203\n",
            "loss = 52.169891357421875\n",
            "loss = 52.17329788208008\n",
            "loss = 52.14598846435547\n",
            "loss = 52.160736083984375\n",
            "loss = 52.128150939941406\n",
            "loss = 52.168888092041016\n",
            "loss = 52.13983917236328\n",
            "loss = 52.12409210205078\n",
            "loss = 52.14338302612305\n",
            "loss = 52.10930633544922\n",
            "loss = 52.136817932128906\n",
            "loss = 52.12104034423828\n",
            "loss = 52.11285400390625\n",
            "loss = 52.1568489074707\n",
            "loss = 52.101348876953125\n",
            "loss = 52.13826370239258\n",
            "loss = 52.121795654296875\n",
            "loss = 52.09663009643555\n",
            "loss = 52.145835876464844\n",
            "loss = 52.10306930541992\n",
            "loss = 52.130104064941406\n",
            "loss = 52.099342346191406\n",
            "loss = 52.098506927490234\n",
            "loss = 52.087711334228516\n",
            "loss = 52.090538024902344\n",
            "loss = 52.125980377197266\n",
            "loss = 52.0963020324707\n",
            "loss = 52.09962844848633\n",
            "loss = 52.10820388793945\n",
            "loss = 52.126014709472656\n",
            "loss = 52.135894775390625\n",
            "loss = 52.082618713378906\n",
            "loss = 52.09716033935547\n",
            "loss = 52.11397171020508\n",
            "loss = 52.1329231262207\n",
            "loss = 52.10321044921875\n",
            "loss = 52.09278106689453\n",
            "loss = 52.15365982055664\n",
            "loss = 52.15486526489258\n",
            "loss = 52.108497619628906\n",
            "loss = 52.107086181640625\n",
            "loss = 52.11577606201172\n",
            "loss = 52.097572326660156\n",
            "loss = 52.080013275146484\n",
            "loss = 52.055816650390625\n",
            "loss = 52.1049919128418\n",
            "loss = 52.088436126708984\n",
            "loss = 52.06666946411133\n",
            "loss = 52.03999328613281\n",
            "loss = 52.062007904052734\n",
            "loss = 52.07651138305664\n",
            "loss = 52.04131317138672\n",
            "loss = 52.054744720458984\n",
            "loss = 52.0564079284668\n",
            "loss = 52.0596809387207\n",
            "loss = 52.09421157836914\n",
            "loss = 52.0509033203125\n",
            "loss = 52.04140853881836\n",
            "loss = 52.107566833496094\n",
            "loss = 52.04413604736328\n",
            "loss = 52.073570251464844\n",
            "loss = 52.037174224853516\n",
            "loss = 52.051979064941406\n",
            "loss = 52.041996002197266\n",
            "loss = 52.048179626464844\n",
            "loss = 52.093929290771484\n",
            "loss = 52.037681579589844\n",
            "loss = 52.03085708618164\n",
            "loss = 52.10114288330078\n",
            "loss = 52.06303787231445\n",
            "loss = 52.08424377441406\n",
            "loss = 52.03342056274414\n",
            "loss = 52.05244827270508\n",
            "loss = 52.08330154418945\n",
            "loss = 52.02370834350586\n",
            "loss = 52.08555221557617\n",
            "loss = 52.0186767578125\n",
            "loss = 52.01749038696289\n",
            "loss = 52.03114318847656\n",
            "loss = 51.99504089355469\n",
            "loss = 52.0577278137207\n",
            "loss = 52.02882766723633\n",
            "loss = 51.99803161621094\n",
            "loss = 52.0156135559082\n",
            "loss = 51.98691940307617\n",
            "loss = 52.040061950683594\n",
            "loss = 51.98722457885742\n",
            "loss = 52.00092315673828\n",
            "loss = 52.019596099853516\n",
            "loss = 52.01397705078125\n",
            "loss = 52.087135314941406\n",
            "loss = 52.007999420166016\n",
            "loss = 51.98889923095703\n",
            "loss = 52.08428192138672\n",
            "loss = 51.98194885253906\n",
            "loss = 52.073753356933594\n",
            "loss = 52.00731658935547\n",
            "loss = 51.981842041015625\n",
            "loss = 52.063812255859375\n",
            "loss = 52.02784729003906\n",
            "loss = 52.096343994140625\n",
            "loss = 52.056739807128906\n",
            "loss = 51.99891662597656\n",
            "loss = 52.01726150512695\n",
            "loss = 52.014060974121094\n",
            "loss = 52.061370849609375\n",
            "loss = 52.01481628417969\n",
            "loss = 51.96561050415039\n",
            "loss = 51.97464370727539\n",
            "loss = 51.98273849487305\n",
            "loss = 52.023990631103516\n",
            "loss = 51.97956848144531\n",
            "loss = 51.951759338378906\n",
            "loss = 52.060585021972656\n",
            "loss = 51.95189666748047\n",
            "loss = 52.01493835449219\n",
            "loss = 51.980377197265625\n",
            "loss = 51.94416427612305\n",
            "loss = 52.019527435302734\n",
            "loss = 51.94794845581055\n",
            "loss = 51.9808464050293\n",
            "loss = 51.96239471435547\n",
            "loss = 51.95900344848633\n",
            "loss = 51.97421646118164\n",
            "loss = 51.940147399902344\n",
            "loss = 51.97573471069336\n",
            "loss = 51.94712448120117\n",
            "loss = 51.923004150390625\n",
            "loss = 51.96473693847656\n",
            "loss = 51.929298400878906\n",
            "loss = 51.9608154296875\n",
            "loss = 51.92243194580078\n",
            "loss = 51.929931640625\n",
            "loss = 51.987144470214844\n",
            "loss = 51.972808837890625\n",
            "loss = 52.01858901977539\n",
            "loss = 51.94754409790039\n",
            "loss = 51.92410659790039\n",
            "loss = 52.004249572753906\n",
            "loss = 51.974388122558594\n",
            "loss = 52.09972381591797\n",
            "loss = 52.13313674926758\n",
            "loss = 52.14178466796875\n",
            "loss = 52.025848388671875\n",
            "loss = 51.94850540161133\n",
            "loss = 52.05613708496094\n",
            "loss = 52.105445861816406\n",
            "loss = 52.093841552734375\n",
            "loss = 51.991947174072266\n",
            "loss = 51.967926025390625\n",
            "loss = 52.080081939697266\n",
            "loss = 52.06706619262695\n",
            "loss = 51.98848342895508\n",
            "loss = 51.954036712646484\n",
            "loss = 52.0114860534668\n",
            "loss = 52.04544448852539\n",
            "loss = 51.99246597290039\n",
            "loss = 51.945892333984375\n",
            "loss = 52.090309143066406\n",
            "loss = 52.09090805053711\n",
            "loss = 51.95551681518555\n",
            "loss = 52.02785873413086\n",
            "loss = 52.0363883972168\n",
            "loss = 52.04725646972656\n",
            "loss = 52.02622985839844\n",
            "loss = 51.950042724609375\n",
            "loss = 51.980224609375\n",
            "loss = 51.979862213134766\n",
            "loss = 51.966339111328125\n",
            "loss = 51.92848205566406\n",
            "loss = 51.98113250732422\n",
            "loss = 51.95143127441406\n",
            "loss = 51.91584777832031\n",
            "loss = 51.9568977355957\n",
            "loss = 51.99119567871094\n",
            "loss = 51.93207550048828\n",
            "loss = 51.92390823364258\n",
            "loss = 51.93155288696289\n",
            "loss = 51.90608596801758\n",
            "loss = 51.91954803466797\n",
            "loss = 51.961570739746094\n",
            "loss = 51.95442581176758\n",
            "loss = 51.91557312011719\n",
            "loss = 51.916465759277344\n",
            "loss = 51.964378356933594\n",
            "loss = 51.92445373535156\n",
            "loss = 51.939998626708984\n",
            "loss = 51.95263671875\n",
            "loss = 51.912574768066406\n",
            "loss = 51.93733215332031\n",
            "loss = 51.92753219604492\n",
            "loss = 51.933040618896484\n",
            "loss = 52.01703643798828\n",
            "loss = 52.058414459228516\n",
            "loss = 51.95362854003906\n",
            "loss = 51.92683410644531\n",
            "loss = 51.95866012573242\n",
            "loss = 51.96253967285156\n",
            "loss = 51.93681335449219\n",
            "loss = 51.88279724121094\n",
            "loss = 51.890830993652344\n",
            "loss = 51.92378234863281\n",
            "loss = 51.93489456176758\n",
            "loss = 51.949344635009766\n",
            "loss = 51.898902893066406\n",
            "loss = 51.90184783935547\n",
            "loss = 51.92396545410156\n",
            "loss = 51.946590423583984\n",
            "loss = 51.90974044799805\n",
            "loss = 51.94172286987305\n",
            "loss = 51.920509338378906\n",
            "loss = 51.974281311035156\n",
            "loss = 51.921409606933594\n",
            "loss = 51.858272552490234\n",
            "loss = 51.936527252197266\n",
            "loss = 51.96216583251953\n",
            "loss = 51.908538818359375\n",
            "loss = 51.915672302246094\n",
            "loss = 51.92549514770508\n",
            "loss = 51.95830154418945\n",
            "loss = 51.96861267089844\n",
            "loss = 51.94426345825195\n",
            "loss = 51.925865173339844\n",
            "loss = 51.94076919555664\n",
            "loss = 51.9307861328125\n",
            "loss = 51.91205978393555\n",
            "loss = 51.91115951538086\n",
            "loss = 51.92474365234375\n",
            "loss = 51.87559509277344\n",
            "loss = 51.88056182861328\n",
            "loss = 51.919864654541016\n",
            "loss = 51.86321258544922\n",
            "loss = 51.92820739746094\n",
            "loss = 52.0070915222168\n",
            "loss = 52.0666618347168\n",
            "loss = 51.9531364440918\n",
            "loss = 51.90071487426758\n",
            "loss = 51.9599494934082\n",
            "loss = 51.96454620361328\n",
            "loss = 51.87833786010742\n",
            "loss = 51.8654670715332\n",
            "loss = 51.9737663269043\n",
            "loss = 51.86964797973633\n",
            "loss = 51.88475036621094\n",
            "loss = 51.87027359008789\n",
            "loss = 51.85584259033203\n",
            "loss = 51.919593811035156\n",
            "loss = 51.91823959350586\n",
            "loss = 51.89351272583008\n",
            "loss = 51.91116714477539\n",
            "loss = 51.961585998535156\n",
            "loss = 51.8751335144043\n",
            "loss = 51.864627838134766\n",
            "loss = 51.96586990356445\n",
            "loss = 51.90187072753906\n",
            "loss = 51.92047119140625\n",
            "loss = 51.88883972167969\n",
            "loss = 51.87090301513672\n",
            "loss = 51.89976119995117\n",
            "loss = 51.92002487182617\n",
            "loss = 51.84225845336914\n",
            "loss = 51.84751892089844\n",
            "loss = 51.844078063964844\n",
            "loss = 51.8528938293457\n",
            "loss = 51.87689971923828\n",
            "loss = 51.8754768371582\n",
            "loss = 51.881038665771484\n",
            "loss = 51.90370178222656\n",
            "loss = 51.940711975097656\n",
            "loss = 51.890689849853516\n",
            "loss = 51.86008071899414\n",
            "loss = 51.929527282714844\n",
            "loss = 51.893550872802734\n",
            "loss = 51.885780334472656\n",
            "loss = 51.864166259765625\n",
            "loss = 51.84272766113281\n",
            "loss = 51.93185806274414\n",
            "loss = 51.84718322753906\n",
            "loss = 51.870811462402344\n",
            "loss = 51.83280563354492\n",
            "loss = 51.902557373046875\n",
            "loss = 51.961307525634766\n",
            "loss = 51.8871955871582\n",
            "loss = 51.89330291748047\n",
            "loss = 51.95325469970703\n",
            "loss = 51.88768005371094\n",
            "loss = 51.86304473876953\n",
            "loss = 51.88470458984375\n",
            "loss = 51.92405700683594\n",
            "loss = 51.907894134521484\n",
            "loss = 51.858314514160156\n",
            "loss = 51.90095901489258\n",
            "loss = 51.873046875\n",
            "loss = 51.85556411743164\n",
            "loss = 51.801536560058594\n",
            "loss = 51.751529693603516\n",
            "loss = 51.867034912109375\n",
            "loss = 51.757179260253906\n",
            "loss = 51.81593704223633\n",
            "loss = 51.75228500366211\n",
            "loss = 51.786739349365234\n",
            "loss = 51.74549102783203\n",
            "loss = 51.753421783447266\n",
            "loss = 51.74182891845703\n",
            "loss = 51.707237243652344\n",
            "loss = 51.721290588378906\n",
            "loss = 51.704559326171875\n",
            "loss = 51.743751525878906\n",
            "loss = 51.766395568847656\n",
            "loss = 51.772098541259766\n",
            "loss = 51.75654983520508\n",
            "loss = 51.753116607666016\n",
            "loss = 51.86433029174805\n",
            "loss = 51.887451171875\n",
            "loss = 51.78293228149414\n",
            "loss = 51.71839141845703\n",
            "loss = 51.761112213134766\n",
            "loss = 51.829586029052734\n",
            "loss = 51.805702209472656\n",
            "loss = 51.73265838623047\n",
            "loss = 51.711158752441406\n",
            "loss = 51.83793258666992\n",
            "loss = 51.903751373291016\n",
            "loss = 51.813114166259766\n",
            "loss = 51.726566314697266\n",
            "loss = 51.7593994140625\n",
            "loss = 51.80078887939453\n",
            "loss = 51.73408508300781\n",
            "loss = 51.70683288574219\n",
            "loss = 51.72666931152344\n",
            "loss = 51.747257232666016\n",
            "loss = 51.73857116699219\n",
            "loss = 51.71571731567383\n",
            "loss = 51.68473434448242\n",
            "loss = 51.69890213012695\n",
            "loss = 51.65517044067383\n",
            "loss = 51.67121505737305\n",
            "loss = 51.66020202636719\n",
            "loss = 51.75053024291992\n",
            "loss = 51.76582717895508\n",
            "loss = 51.65449905395508\n",
            "loss = 51.71126937866211\n",
            "loss = 51.66156005859375\n",
            "loss = 51.66777801513672\n",
            "loss = 51.687339782714844\n",
            "loss = 51.62260437011719\n",
            "loss = 51.715576171875\n",
            "loss = 51.68644332885742\n",
            "loss = 51.69300842285156\n",
            "loss = 51.680545806884766\n",
            "loss = 51.68169403076172\n",
            "loss = 51.67384719848633\n",
            "loss = 51.62612533569336\n",
            "loss = 51.63402557373047\n",
            "loss = 51.606632232666016\n",
            "loss = 51.629493713378906\n",
            "loss = 51.65955352783203\n",
            "loss = 51.7056999206543\n",
            "loss = 51.65380096435547\n",
            "loss = 51.62820053100586\n",
            "loss = 51.63191223144531\n",
            "loss = 51.62380599975586\n",
            "loss = 51.66798400878906\n",
            "loss = 51.635406494140625\n",
            "loss = 51.6017951965332\n",
            "loss = 51.66990280151367\n",
            "loss = 51.649925231933594\n",
            "loss = 51.6878547668457\n",
            "loss = 51.65582275390625\n",
            "loss = 51.602657318115234\n",
            "loss = 51.629966735839844\n",
            "loss = 51.66973876953125\n",
            "loss = 51.71548843383789\n",
            "loss = 51.641361236572266\n",
            "loss = 51.653770446777344\n",
            "loss = 51.5551872253418\n",
            "loss = 51.65470886230469\n",
            "loss = 51.63117599487305\n",
            "loss = 51.63155746459961\n",
            "loss = 51.63819122314453\n",
            "loss = 51.62575149536133\n",
            "loss = 51.65150451660156\n",
            "loss = 51.5536994934082\n",
            "loss = 51.62224578857422\n",
            "loss = 51.61909484863281\n",
            "loss = 51.649452209472656\n",
            "loss = 51.706932067871094\n",
            "loss = 51.58259201049805\n",
            "loss = 51.68597412109375\n",
            "loss = 51.61309814453125\n",
            "loss = 51.641963958740234\n",
            "loss = 51.64452362060547\n",
            "loss = 51.564292907714844\n",
            "loss = 51.5794563293457\n",
            "loss = 51.59223556518555\n",
            "loss = 51.59278869628906\n",
            "loss = 51.64353561401367\n",
            "loss = 51.558406829833984\n",
            "loss = 51.627227783203125\n",
            "loss = 51.596553802490234\n",
            "loss = 51.584075927734375\n",
            "loss = 51.54066848754883\n",
            "loss = 51.51966857910156\n",
            "loss = 51.57806396484375\n",
            "loss = 51.55303955078125\n",
            "loss = 51.65678024291992\n",
            "loss = 51.64206314086914\n",
            "loss = 51.62301254272461\n",
            "loss = 51.56117248535156\n",
            "loss = 51.53558349609375\n",
            "loss = 51.53645706176758\n",
            "loss = 51.533260345458984\n",
            "loss = 51.52323913574219\n",
            "loss = 51.55232238769531\n",
            "loss = 51.54867935180664\n",
            "loss = 51.52701187133789\n",
            "loss = 51.5280876159668\n",
            "loss = 51.531253814697266\n",
            "loss = 51.5015869140625\n",
            "loss = 51.512359619140625\n",
            "loss = 51.491371154785156\n",
            "loss = 51.530372619628906\n",
            "loss = 51.53575897216797\n",
            "loss = 51.49686813354492\n",
            "loss = 51.55437088012695\n",
            "loss = 51.50222396850586\n",
            "loss = 51.55921936035156\n",
            "loss = 51.54585647583008\n",
            "loss = 51.49901580810547\n",
            "loss = 51.577178955078125\n",
            "loss = 51.50979232788086\n",
            "loss = 51.629112243652344\n",
            "loss = 51.60868453979492\n",
            "loss = 51.58663558959961\n",
            "loss = 51.55036544799805\n",
            "loss = 51.507957458496094\n",
            "loss = 51.47019577026367\n",
            "loss = 51.48626708984375\n",
            "loss = 51.50579071044922\n",
            "loss = 51.54338455200195\n",
            "loss = 51.56939697265625\n",
            "loss = 51.61652374267578\n",
            "loss = 51.5606689453125\n",
            "loss = 51.514652252197266\n",
            "loss = 51.45532989501953\n",
            "loss = 51.45934295654297\n",
            "loss = 51.502716064453125\n",
            "loss = 51.51961898803711\n",
            "loss = 51.53730773925781\n",
            "loss = 51.49586486816406\n",
            "loss = 51.49120330810547\n",
            "loss = 51.5064582824707\n",
            "loss = 51.46730422973633\n",
            "loss = 51.47011184692383\n",
            "loss = 51.50684356689453\n",
            "loss = 51.52029037475586\n",
            "loss = 51.43217849731445\n",
            "loss = 51.47774124145508\n",
            "loss = 51.54397964477539\n",
            "loss = 51.53076934814453\n",
            "loss = 51.55440902709961\n",
            "loss = 51.507747650146484\n",
            "loss = 51.45054244995117\n",
            "loss = 51.44830322265625\n",
            "loss = 51.505062103271484\n",
            "loss = 51.50122833251953\n",
            "loss = 51.44633865356445\n",
            "loss = 51.4370002746582\n",
            "loss = 51.46834182739258\n",
            "loss = 51.48640441894531\n",
            "loss = 51.504825592041016\n",
            "loss = 51.47321319580078\n",
            "loss = 51.45381164550781\n",
            "loss = 51.46684646606445\n",
            "loss = 51.452659606933594\n",
            "loss = 51.42719650268555\n",
            "loss = 51.390533447265625\n",
            "loss = 51.418212890625\n",
            "loss = 51.401023864746094\n",
            "loss = 51.42015838623047\n",
            "loss = 51.51272964477539\n",
            "loss = 51.46025085449219\n",
            "loss = 51.58087158203125\n",
            "loss = 51.63396453857422\n",
            "loss = 51.66106414794922\n",
            "loss = 51.58220672607422\n",
            "loss = 51.46592712402344\n",
            "loss = 51.40144729614258\n",
            "loss = 51.379547119140625\n",
            "loss = 51.370548248291016\n",
            "loss = 51.48159408569336\n",
            "loss = 51.5025634765625\n",
            "loss = 51.46091079711914\n",
            "loss = 51.442176818847656\n",
            "loss = 51.401466369628906\n",
            "loss = 51.394187927246094\n",
            "loss = 51.37208938598633\n",
            "loss = 51.36814880371094\n",
            "loss = 51.342533111572266\n",
            "loss = 51.35309600830078\n",
            "loss = 51.38846969604492\n",
            "loss = 51.45480728149414\n",
            "loss = 51.47631072998047\n",
            "loss = 51.453670501708984\n",
            "loss = 51.404075622558594\n",
            "loss = 51.369232177734375\n",
            "loss = 51.42416763305664\n",
            "loss = 51.55341720581055\n",
            "loss = 51.633445739746094\n",
            "loss = 51.56653594970703\n",
            "loss = 51.408939361572266\n",
            "loss = 51.380592346191406\n",
            "loss = 51.375099182128906\n",
            "loss = 51.37103271484375\n",
            "loss = 51.41497802734375\n",
            "loss = 51.360836029052734\n",
            "loss = 51.35577392578125\n",
            "loss = 51.381038665771484\n",
            "loss = 51.43010711669922\n",
            "loss = 51.40841293334961\n",
            "loss = 51.41546630859375\n",
            "loss = 51.35385513305664\n",
            "loss = 51.36910629272461\n",
            "loss = 51.36551284790039\n",
            "loss = 51.339683532714844\n",
            "loss = 51.418846130371094\n",
            "loss = 51.460670471191406\n",
            "loss = 51.40182113647461\n",
            "loss = 51.39644241333008\n",
            "loss = 51.45039367675781\n",
            "loss = 51.42587661743164\n",
            "loss = 51.406707763671875\n",
            "loss = 51.401485443115234\n",
            "loss = 51.35451126098633\n",
            "loss = 51.415496826171875\n",
            "loss = 51.39948654174805\n",
            "loss = 51.360992431640625\n",
            "loss = 51.3872184753418\n",
            "loss = 51.37784194946289\n",
            "loss = 51.43260192871094\n",
            "loss = 51.414146423339844\n",
            "loss = 51.38311004638672\n",
            "loss = 51.34776306152344\n",
            "loss = 51.32120132446289\n",
            "loss = 51.36962890625\n",
            "loss = 51.356075286865234\n",
            "loss = 51.30080795288086\n",
            "loss = 51.33053207397461\n",
            "loss = 51.33811569213867\n",
            "loss = 51.324825286865234\n",
            "loss = 51.40925598144531\n",
            "loss = 51.484657287597656\n",
            "loss = 51.446014404296875\n",
            "loss = 51.347660064697266\n",
            "loss = 51.383949279785156\n",
            "loss = 51.38262176513672\n",
            "loss = 51.406639099121094\n",
            "loss = 51.38459777832031\n",
            "loss = 51.38787841796875\n",
            "loss = 51.301700592041016\n",
            "loss = 51.311187744140625\n",
            "loss = 51.33285903930664\n",
            "loss = 51.33332061767578\n",
            "loss = 51.34766387939453\n",
            "loss = 51.38451385498047\n",
            "loss = 51.3060302734375\n",
            "loss = 51.32980728149414\n",
            "loss = 51.34275817871094\n",
            "loss = 51.30503463745117\n",
            "loss = 51.31624984741211\n",
            "loss = 51.33930969238281\n",
            "loss = 51.280433654785156\n",
            "loss = 51.328487396240234\n",
            "loss = 51.31886672973633\n",
            "loss = 51.385704040527344\n",
            "loss = 51.318084716796875\n",
            "loss = 51.374881744384766\n",
            "loss = 51.2988395690918\n",
            "loss = 51.44607925415039\n",
            "loss = 51.472572326660156\n",
            "loss = 51.54790496826172\n",
            "loss = 51.457515716552734\n",
            "loss = 51.41897964477539\n",
            "loss = 51.31867218017578\n",
            "loss = 51.286014556884766\n",
            "loss = 51.34539031982422\n",
            "loss = 51.293540954589844\n",
            "loss = 51.415191650390625\n",
            "loss = 51.41075897216797\n",
            "loss = 51.45891189575195\n",
            "loss = 51.43254089355469\n",
            "loss = 51.415199279785156\n",
            "loss = 51.43374252319336\n",
            "loss = 51.37481689453125\n",
            "loss = 51.363258361816406\n",
            "loss = 51.31220245361328\n",
            "loss = 51.31794738769531\n",
            "loss = 51.313873291015625\n",
            "loss = 51.39156723022461\n",
            "loss = 51.348228454589844\n",
            "loss = 51.30694580078125\n",
            "loss = 51.360694885253906\n",
            "loss = 51.361419677734375\n",
            "loss = 51.46021270751953\n",
            "loss = 51.489166259765625\n",
            "loss = 51.43234634399414\n",
            "loss = 51.30211639404297\n",
            "loss = 51.29252624511719\n",
            "loss = 51.30521774291992\n",
            "loss = 51.37668228149414\n",
            "loss = 51.467098236083984\n",
            "loss = 51.53289031982422\n",
            "loss = 51.40922927856445\n",
            "loss = 51.34682083129883\n",
            "loss = 51.354549407958984\n",
            "loss = 51.466644287109375\n",
            "loss = 51.55772018432617\n",
            "loss = 51.43292236328125\n",
            "loss = 51.3284797668457\n",
            "loss = 51.24745178222656\n",
            "loss = 51.370872497558594\n",
            "loss = 51.453556060791016\n",
            "loss = 51.37492370605469\n",
            "loss = 51.24382019042969\n",
            "loss = 51.23747253417969\n",
            "loss = 51.357730865478516\n",
            "loss = 51.391197204589844\n",
            "loss = 51.297054290771484\n",
            "loss = 51.27301788330078\n",
            "loss = 51.239707946777344\n",
            "loss = 51.2583122253418\n",
            "loss = 51.277259826660156\n",
            "loss = 51.23473358154297\n",
            "loss = 51.27061080932617\n",
            "loss = 51.247642517089844\n",
            "loss = 51.25780487060547\n",
            "loss = 51.22776412963867\n",
            "loss = 51.22708511352539\n",
            "loss = 51.28082275390625\n",
            "loss = 51.321022033691406\n",
            "loss = 51.22047805786133\n",
            "loss = 51.283203125\n",
            "loss = 51.283939361572266\n",
            "loss = 51.278358459472656\n",
            "loss = 51.22843551635742\n",
            "loss = 51.20703887939453\n",
            "loss = 51.24106216430664\n",
            "loss = 51.21412658691406\n",
            "loss = 51.20854187011719\n",
            "loss = 51.25801086425781\n",
            "loss = 51.258785247802734\n",
            "loss = 51.215484619140625\n",
            "loss = 51.15562438964844\n",
            "loss = 51.30881881713867\n",
            "loss = 51.35932159423828\n",
            "loss = 51.41924285888672\n",
            "loss = 51.31504440307617\n",
            "loss = 51.32585906982422\n",
            "loss = 51.24845886230469\n",
            "loss = 51.26578903198242\n",
            "loss = 51.31267166137695\n",
            "loss = 51.30741882324219\n",
            "loss = 51.277435302734375\n",
            "loss = 51.21982192993164\n",
            "loss = 51.315818786621094\n",
            "loss = 51.279605865478516\n",
            "loss = 51.27863311767578\n",
            "loss = 51.2130126953125\n",
            "loss = 51.17790222167969\n",
            "loss = 51.247474670410156\n",
            "loss = 51.410640716552734\n",
            "loss = 51.343143463134766\n",
            "loss = 51.31989288330078\n",
            "loss = 51.21072769165039\n",
            "loss = 51.2100944519043\n",
            "loss = 51.28417205810547\n",
            "loss = 51.36931228637695\n",
            "loss = 51.283905029296875\n",
            "loss = 51.20210647583008\n",
            "loss = 51.198883056640625\n",
            "loss = 51.33689498901367\n",
            "loss = 51.466583251953125\n",
            "loss = 51.339012145996094\n",
            "loss = 51.186214447021484\n",
            "loss = 51.28586196899414\n",
            "loss = 51.27494430541992\n",
            "loss = 51.32542419433594\n",
            "loss = 51.33442306518555\n",
            "loss = 51.26006317138672\n",
            "loss = 51.19419860839844\n",
            "loss = 51.27223587036133\n",
            "loss = 51.32768249511719\n",
            "loss = 51.215362548828125\n",
            "loss = 51.229129791259766\n",
            "loss = 51.25743103027344\n",
            "loss = 51.24553298950195\n",
            "loss = 51.226295471191406\n",
            "loss = 51.18009567260742\n",
            "loss = 51.186439514160156\n",
            "loss = 51.184364318847656\n",
            "loss = 51.228031158447266\n",
            "loss = 51.292991638183594\n",
            "loss = 51.272552490234375\n",
            "loss = 51.160301208496094\n",
            "loss = 51.146827697753906\n",
            "loss = 51.274051666259766\n",
            "loss = 51.3172607421875\n",
            "loss = 51.23200988769531\n",
            "loss = 51.18834686279297\n",
            "loss = 51.197906494140625\n",
            "loss = 51.218597412109375\n",
            "loss = 51.18931579589844\n",
            "loss = 51.19184875488281\n",
            "loss = 51.1640510559082\n",
            "loss = 51.1733512878418\n",
            "loss = 51.19757843017578\n",
            "loss = 51.22597122192383\n",
            "loss = 51.19133377075195\n",
            "loss = 51.134708404541016\n",
            "loss = 51.19176483154297\n",
            "loss = 51.20580291748047\n",
            "loss = 51.142333984375\n",
            "loss = 51.16872787475586\n",
            "loss = 51.2130126953125\n",
            "loss = 51.16922378540039\n",
            "loss = 51.128028869628906\n",
            "loss = 51.16115951538086\n",
            "loss = 51.17551040649414\n",
            "loss = 51.171600341796875\n",
            "loss = 51.23134994506836\n",
            "loss = 51.22591781616211\n",
            "loss = 51.21607208251953\n",
            "loss = 51.13054275512695\n",
            "loss = 51.222747802734375\n",
            "loss = 51.31037521362305\n",
            "loss = 51.273170471191406\n",
            "loss = 51.219940185546875\n",
            "loss = 51.185550689697266\n",
            "loss = 51.128662109375\n",
            "loss = 51.1250114440918\n",
            "loss = 51.235286712646484\n",
            "loss = 51.23846435546875\n",
            "loss = 51.21897506713867\n",
            "loss = 51.210018157958984\n",
            "loss = 51.16178512573242\n",
            "loss = 51.235042572021484\n",
            "loss = 51.17459487915039\n",
            "loss = 51.214324951171875\n",
            "loss = 51.162620544433594\n",
            "loss = 51.198097229003906\n",
            "loss = 51.179725646972656\n",
            "loss = 51.161136627197266\n",
            "loss = 51.16054916381836\n",
            "loss = 51.142372131347656\n",
            "loss = 51.15235900878906\n",
            "loss = 51.177589416503906\n",
            "loss = 51.19353103637695\n",
            "loss = 51.182167053222656\n",
            "loss = 51.18839645385742\n",
            "loss = 51.17426681518555\n",
            "loss = 51.171424865722656\n",
            "loss = 51.14202880859375\n",
            "loss = 51.176292419433594\n",
            "loss = 51.18122100830078\n",
            "loss = 51.15714645385742\n",
            "loss = 51.14093017578125\n",
            "loss = 51.15987014770508\n",
            "loss = 51.193138122558594\n",
            "loss = 51.13397216796875\n",
            "loss = 51.15498352050781\n",
            "loss = 51.130714416503906\n",
            "loss = 51.179481506347656\n",
            "loss = 51.123260498046875\n",
            "loss = 51.156028747558594\n",
            "loss = 51.089012145996094\n",
            "loss = 51.172119140625\n",
            "loss = 51.16777038574219\n",
            "loss = 51.181983947753906\n",
            "loss = 51.13083267211914\n",
            "loss = 51.091129302978516\n",
            "loss = 51.108787536621094\n",
            "loss = 51.12102508544922\n",
            "loss = 51.109989166259766\n",
            "loss = 51.12044143676758\n",
            "loss = 51.13840103149414\n",
            "loss = 51.15594482421875\n",
            "loss = 51.14009475708008\n",
            "loss = 51.118961334228516\n",
            "loss = 51.086463928222656\n",
            "loss = 51.13029098510742\n",
            "loss = 51.220603942871094\n",
            "loss = 51.279972076416016\n",
            "loss = 51.21931457519531\n",
            "loss = 51.19731140136719\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRlkcpT0D-a1"
      },
      "source": [
        "## MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4GfdMRhD-a1"
      },
      "source": [
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyQ4gP46D-a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2010f553-9d69-4c31-84bb-4f5c3ce98aeb"
      },
      "source": [
        "data = MNIST(\".\", download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.18MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfX2XnGD-a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36be763-c8d7-4c54-d31c-135ab8cccc0c"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7fwSvMkD-a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "edec01de-d010-480c-ccb4-562904406262"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "img, y = data[np.random.randint(1, 60000)]\n",
        "print(y)\n",
        "img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEElEQVR4AWNgGMqAVzbj6d9PvfLY/KB76O+fP3/+/mkCS7IgKzEoCOD5nnmbQWydGrIwmD39458/0yUZGFKf/ilDlWQxe/r390MjBpbNf//+/5uFKun/58/jWqAQ12qgnR+0USTr/v55ABHhvfjnSyCq3M+/acIQkenf/oBMQAC3v39PQnhSs/7+3QeTgHjF8D+DOVCE3UhtCtf/t+tRJU+8Ezr2HyhpABLePxkmCaUTgaECChkQRvMjUIVx3cOHtUVq7X8/JaLpg3PVjv7ZIQPnMTAhmEBWljnDxScoIgiO1Oc/p3gRXAaUWHnyn+HFZyRJZOb0v38mciILILHV3v5dpYrER2Gq7f6ojyJAAQcAqbprHtzkiU0AAAAASUVORK5CYII=\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+pIIJrqeOC3ieWaRgqRopZmJ6AAdTXTX3w28YaZobaze6FcwWKDLu5UMg9WTO4D6iuVrb8J+GL7xh4jttGsCiyzElpHPyxoOWY/Qdu9d3J4p0/wALMfDvw2043epMfJn1tohLPO+cHyQMhVPGD79M/NW/4tu7XwT8MUsb/T2Txd4gt9t5JJcvNIFyC7uzE4LcfKOMk9cV4VV/RtZ1Dw/q0Gp6Xctb3cDbkdefqCDwQfQ17x8N/HvivxTqM+pajJp2m+H9Li3XtxFbpGJTg4QsxOCepxgDA6ZGfF/Gfii68YeKLvV7piQ7bIVKgbIgTtXj2rAorTj8RatF4ek0CO9ddLkm897cAAM+MZJxn8M44FZlFf/Z\n"
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, y = data[2]\n",
        "img"
      ],
      "metadata": {
        "id": "qSkUnhyaWfGG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "5394dce0-dd3e-4b7a-c33b-5d71d17e1249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2ElEQVR4AWNgGArA+YU62JlMINIuENXJpmcgfLCkQxCKJJOiHCNC4M5iBBvIkv63CMIH6wQTCPk5DLcRknriCAkQi59hN0LSixNFUlyR4SlCUp3hKrJsj/itzxA+C5g6DZfk84hxY2j+gCwpBOToMznLsEUzfT/5k+UsVC3IQ9PSPzxiYNBj/PPt2skzB18+EWSDSoKMzXpoBSQfbbx2AiSYJnoPRGEHK/91wiTQ/A8W3oBPEibHgEUnoypMFovkf7gYnAFTDaQtYWwskoi4xJTc/h+mkVY0AIN5LEcoO8xxAAAAAElFTkSuQmCC\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APBorO4ntri5iiZobcKZXHRNxwM/U1BWjYaLc6jpupX8LRiHT40km3E5O5goAwDzznnHQ1nV6J4a0i4vPg/4lewsrq8vLnUbWEx28ZcqiAvuwOepI/KsSD4b+MJ4RM2hXNvCefMuytuo4z1kKiul13TY/CHwbtbA3drc3mu6k07y2jrInlQDbs3j72GYHjjJP4+Y1astTv8ATWdrC+ubVnADGCVkLfXB5pt3f3moS+be3c9zJ03zSFz+Zru/iMJV8K+Al3Yt/wCxgUQdA5b5j9T8v5V55RRVie/vLqC3guLueaG2UpBHJIWWJSckKD90Z9Kr1//Z\n"
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE1RB4gBQ18g",
        "outputId": "85dd554a-c5ce-4105-a7bc-f39ace4fb635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__orig_bases__',\n",
              " '__parameters__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_check_exists',\n",
              " '_check_legacy_exist',\n",
              " '_format_transform_repr',\n",
              " '_is_protocol',\n",
              " '_load_data',\n",
              " '_load_legacy_data',\n",
              " '_repr_indent',\n",
              " 'class_to_idx',\n",
              " 'classes',\n",
              " 'data',\n",
              " 'download',\n",
              " 'extra_repr',\n",
              " 'mirrors',\n",
              " 'processed_folder',\n",
              " 'raw_folder',\n",
              " 'resources',\n",
              " 'root',\n",
              " 'target_transform',\n",
              " 'targets',\n",
              " 'test_data',\n",
              " 'test_file',\n",
              " 'test_labels',\n",
              " 'train',\n",
              " 'train_data',\n",
              " 'train_labels',\n",
              " 'training_file',\n",
              " 'transform',\n",
              " 'transforms']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdata.test_data.shape"
      ],
      "metadata": {
        "id": "FzZMa_mPamd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.train_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIx9a8bxRAcd",
        "outputId": "87e31867-550f-4a00-ebfa-f98b04cf6957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3giZTnRiD-a-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2589ba2-ac7a-49d5-c64e-c2a3f02e3ce9"
      },
      "source": [
        "print(data.train_data[2].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsZHdAMlD-a_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a99d6d7-5b21-4841-a5be-e613aef08897"
      },
      "source": [
        "print(data.train_labels[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:66: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROmpaSMVD-bA"
      },
      "source": [
        "### MNIST Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHhKarpfD-bB"
      },
      "source": [
        "model = torch.nn.Sequential(  # 28*28 = 784\n",
        "    torch.nn.Linear(784, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 10),\n",
        "    torch.nn.LogSoftmax(dim=1),\n",
        ").to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Q59QCED-bC"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss().to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehneQZatD-bG"
      },
      "source": [
        "sample = np.random.choice(range(len(data.train_data)), 1000)\n",
        "x = data.train_data[sample].reshape(1000, -1).float() / 255\n",
        "yt = data.train_labels[sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucZS9UPAD-bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cf626c-89a0-40f4-a67f-fcc760c4ec40"
      },
      "source": [
        "x.shape, yt.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 784]), torch.Size([1000]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XECFt5PR-Ot",
        "outputId": "aab0a0db-244d-4066-8b82-a9e5a46e4d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x7f3d8e03cac0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdOxW-tYD-bK"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtNhgaED-bL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "44f0dce2-d44f-40c2-87e5-f4e81e4d61d1"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "    sample = np.random.choice(range(len(data.data)), 1000)\n",
        "    x = data.data[sample].reshape(1000, -1).float() / 255\n",
        "    yt = data.targets[sample]\n",
        "\n",
        "    x = x.to(gpu)\n",
        "    yt = yt.to(gpu)\n",
        "\n",
        "    y = model(x)\n",
        "\n",
        "    # input (Tensor) – Predicted unnormalized logits\n",
        "    # target (Tensor) – Ground truth class indices or class probabilities\n",
        "    loss = loss_fn(y, yt)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses += [loss.item()]\n",
        "    # print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BAXeaKHD-bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ec73d6-2eac-450f-e7af-a26720d3793d"
      },
      "source": [
        "x_test = data.train_data[-1000:].reshape(1000, -1).float() / 255\n",
        "y_test = data.train_labels[-1000:]\n",
        "\n",
        "model = model.cpu().eval() # sets the model to evaluation mode\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:66: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VXFOBCjD-bO"
      },
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[4]"
      ],
      "metadata": {
        "id": "Ms69eUDYYMGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ebf824-3a0a-4f33-862c-c892d58a3379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.argmax(dim=1)[4]"
      ],
      "metadata": {
        "id": "6oG-bennMI3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3de26b6-65b6-43f2-cc9f-339b0295d547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0c-JhpD-bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8589c4-2a90-4d3e-fa2c-d428b85bce74"
      },
      "source": [
        "print(\"Accuracy = \", (y_pred.argmax(dim=1) == y_test).sum().float().item() / 1000.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6m7c0qD-bQ"
      },
      "source": [
        "## Course Conclusion\n",
        "\n",
        "1. By now you should have a sufficient introduction to the various ways one can use python for scientific computing. The best way to learn more is to start using python for whatever project you are working on. Only practice will make you comfortable with using python.   \n",
        "\n",
        "- Recommended Project Source: kaggle  \n",
        "\n",
        "- Recommended ML/DL Courses: CS229, 230, 231N, 224 series, 238, 246  \n",
        "\n",
        "2. I appreciate your time to submit the course feedback, which means a lot to me and improvement for this course in the future  \n",
        "\n"
      ]
    }
  ]
}